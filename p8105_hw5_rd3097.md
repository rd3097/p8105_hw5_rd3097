p8105_hw5_rd3097
================
2023-11-13

Necessary Library

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.4     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(broom)
library(patchwork)
```

### Problem 1

``` r
homocide_data<-read.csv("homicide-data.csv")
```

describe the raw data

``` r
tidied_data <- homocide_data |>
  mutate(city_state =  paste(city, state, sep = ","))
disposition_data <- tidied_data|>
  group_by(city_state)|>
  summarise(
    total_homicide = sum(count = n())
  )|>
  ungroup()
unsolved_dispostion_data <- tidied_data|>
  filter(disposition %in% c("Closed without arrest", "Open/No arrest"))|>
  group_by(city_state)|>
  summarise(
    unsolved_homicide = sum(count = n())
  )|>
  ungroup()
  #since Tulsa,AL doesn't have unsolved homicide, we need to manual add it back
new_row<- tibble(city_state = "Tulsa,AL", unsolved_homicide = 0)
unsolved_disposition_new_data<- 
  rbind(unsolved_dispostion_data,new_row)
unsolved_disposition_new_data <- unsolved_disposition_new_data[order(unsolved_disposition_new_data$city_state), ]
```

``` r
baltimore_count<-disposition_data|>
  filter(city_state %in% "Baltimore,MD")
baltimore_unsolved_count<-unsolved_dispostion_data|>
  filter(city_state %in% "Baltimore,MD")
prop_test_baltimore_result <- prop.test(baltimore_unsolved_count$unsolved_homicide,
                                n = baltimore_count$total_homicide, correct = TRUE)
save(prop_test_baltimore_result, file = "prop_test_result.RData")

tidy_baltimore_test<- broom::tidy(prop_test_baltimore_result)
estimated_baltimore_proportion<- tidy_baltimore_test$estimate
confidence_baltimore_interval<- c(tidy_baltimore_test$conf.low,tidy_baltimore_test$conf.high)
```

Then run prop.test for each of the cities in your dataset, and extract
both the proportion of unsolved homicides and the confidence interval
for each.

``` r
prop_test_result <- prop.test(unsolved_disposition_new_data$unsolved_homicide,
                                n = disposition_data$total_homicide, correct = TRUE)
```

    ## Warning in prop.test(unsolved_disposition_new_data$unsolved_homicide, n =
    ## disposition_data$total_homicide, : Chi-squared approximation may be incorrect

``` r
tidy_test<- broom::tidy(prop_test_result)
```

### Problem 2

``` r
file <- list.files(path="data",pattern = "\\.csv$", full.names = TRUE)
file_names <- list.files(path = "data")
data_list <- map(file, ~ read.csv(.x),.id = "subject_name")

#tidy the data
combined_data <- bind_rows(data_list,.id = "subject_name")|>
  mutate(subject_name = file_names,
         subject_name = sub("\\.csv$", "", subject_name))|>
  separate(subject_name, c("arm", "subject_id"), sep = "_")|>
  pivot_longer(cols = starts_with("week"), 
               names_to = "Week", 
               values_to = "Observations")
time <- sub("_", " ", combined_data$Week)
tidied_data<- combined_data|>
  mutate(Week = time)
```

``` r
# make a spaghetti plot showing observations on each subject over time
ggplot(tidied_data, 
       aes(x = factor(time), y = Observations, group = subject_id, color = subject_id)) +
  geom_point() +
  geom_line() +
  facet_grid(.~arm) +
  labs(
    title = "Spaghetti Plot of Observations Over Time",
    x = "Time",
    y = "Value",
    color = "Subject ID"
  ) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

![](p8105_hw5_rd3097_files/figure-gfm/unnamed-chunk-7-1.png)<!-- -->

Based on the spaghetti graph, we can clearly see that the control arms
from the longitudinal study have lower observation values compared to
experimental arms, and the experimental arms fluctuate more frequent
than control arms.

### Problem 3

``` r
# Set parameters, two-sided
set.seed(5000)
n <- 30
sigma <- 5
dataset <- 5000
alpha <- 0.05

#function for test of H:μ=0 using α=0.05 when mu = 0
 
output = vector("list", length = 5000)
for (i in 1:5000) {
  sample_data <-tibble(x = rnorm(n, mean = 0, sd = sigma))
  output[[i]] = t.test(sample_data,mu = 0, conf.level = 0.95)|>
  broom::tidy()}
sample_test<-output|>
  bind_rows()|>
  select(estimate, p.value)|>
  mutate(mu = 0)
```

``` r
# Repeat the simulation for mu = 1, 2, 3, 4, 5, 6
mu_values <- c(1, 2, 3, 4, 5, 6)
outputs <- vector("list", length = 5000)

for (i in 1:5000) {
  for (mu in mu_values) {
    sample_data <- tibble(x = rnorm(n, mean = mu, sd = sigma))
    result <- t.test(sample_data$x, mu = 0, conf.level = 0.95) |> 
      broom::tidy()
    result$mu <- mu  
    outputs[[length(outputs) + 1]] <- result
  }
}

sample_tests <- outputs |> 
  bind_rows() |> 
  select(mu, estimate, p.value)
```

``` r
#Make a plot showing the proportion of times the null was rejected 

total_test <- bind_rows(sample_test,sample_tests)|>
  group_by(mu)
  

plot_1<- total_test|>
  summarize(rejected_null = sum(p.value < 0.05),total = n()) |>
  mutate(proportion = rejected_null / total) |> 
  ggplot(aes(x = mu, y = proportion,color=mu)) +
  geom_point() +
  geom_line()+
  labs(title = "Proportion of times the null rejected based μ",
       x = "Value of μ",
       y = "Proportion",
       caption = "Effect size is positively associated with power") 

plot_1
```

![](p8105_hw5_rd3097_files/figure-gfm/unnamed-chunk-10-1.png)<!-- -->
The association between effect size and power is that effect size is
positively associated with power.

``` r
#Make a plot showing the average estimate of μ on the y axis and the true value of μ on the x axis.

plot_2<- total_test|>
  summarize(average_mu_values = mean(estimate))|>
  ggplot(aes(x = mu, y = average_mu_values,color=mu)) + 
  geom_point() +
  geom_line() +
  labs(title = "Average Estimate of mu Versus True Value of mu",
       x = "True Value of mu",
       y = "Average Estimate of mu") 

#Make a second plot he average estimate of μ only in samples for which the null was rejected on the y axis and the true value of μ on the x axis.          
plot_3<- total_test|>
  filter(p.value < 0.05)|>
  summarize(new_average_mu_values = mean(estimate))|>
  ggplot(aes(x = mu, y = new_average_mu_values,color=mu)) + 
  geom_point() +
  geom_line() +
  labs(title = "Average Estimate of mu Versus True Value of mu When Null was Rejected",
       x = "True Value of mu",
       y = "Average Estimate of mu when null was rejected") 
```

``` r
plot_2 + plot_3
```

![](p8105_hw5_rd3097_files/figure-gfm/patchwork-1.png)<!-- --> From the
graph, we can see that the average estimate of mu is almost the same as
true value of mu. But for samples are only the null that was rejected,
when the power move from 0 to 3, the derivation of average estimate of
mu is larger compared with true value of mu. But when the power move
from 4 to 6, the average estimate of mu becomes almost the same as true
value of mu.
