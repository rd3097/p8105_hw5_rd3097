---
title: "p8105_hw5_rd3097"
output: github_document
date: "2023-11-13"
---

---
title: "p8105_hw5_rd3097"
output: github_document
date: "2023-11-13"
---

Necessary Library
```{r}
library(tidyverse)
library(broom)
library(patchwork)
```

### Problem 1
```{r}
homocide_data<-read.csv("homicide-data.csv")
```

describe the raw data

```{r}
tidied_data <- homocide_data |>
  mutate(city_state =  paste(city, state, sep = ","))
disposition_data <- tidied_data|>
  group_by(city_state)|>
  summarise(
    total_homicide = sum(count = n())
  )|>
  ungroup()
unsolved_dispostion_data <- tidied_data|>
  filter(disposition %in% c("Closed without arrest", "Open/No arrest"))|>
  group_by(city_state)|>
  summarise(
    unsolved_homicide = sum(count = n())
  )|>
  ungroup()
  #since Tulsa,AL doesn't have unsolved homicide, we need to manual add it back
new_row<- tibble(city_state = "Tulsa,AL", unsolved_homicide = 0)
unsolved_disposition_new_data<- 
  rbind(unsolved_dispostion_data,new_row)
unsolved_disposition_new_data <- unsolved_disposition_new_data[order(unsolved_disposition_new_data$city_state), ]

```

```{r}
baltimore_count<-disposition_data|>
  filter(city_state %in% "Baltimore,MD")
baltimore_unsolved_count<-unsolved_dispostion_data|>
  filter(city_state %in% "Baltimore,MD")
prop_test_baltimore_result <- prop.test(baltimore_unsolved_count$unsolved_homicide,
                                n = baltimore_count$total_homicide, correct = TRUE)
save(prop_test_baltimore_result, file = "prop_test_result.RData")

tidy_baltimore_test<- broom::tidy(prop_test_baltimore_result)
estimated_baltimore_proportion<- tidy_baltimore_test$estimate
confidence_baltimore_interval<- c(tidy_baltimore_test$conf.low,tidy_baltimore_test$conf.high)
```

Then run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each.
```{r}
prop_test_result <- prop.test(unsolved_disposition_new_data$unsolved_homicide,
                                n = disposition_data$total_homicide, correct = TRUE)

tidy_test<- broom::tidy(prop_test_result)
```

### Problem 2
```{r}
file <- list.files(path="data",pattern = "\\.csv$", full.names = TRUE)
file_names <- list.files(path = "data")
data_list <- map(file, ~ read.csv(.x),.id = "subject_name")

#tidy the data
combined_data <- bind_rows(data_list,.id = "subject_name")|>
  mutate(subject_name = file_names,
         subject_name = sub("\\.csv$", "", subject_name))|>
  separate(subject_name, c("arm", "subject_id"), sep = "_")|>
  pivot_longer(cols = starts_with("week"), 
               names_to = "Week", 
               values_to = "Observations")
time <- sub("_", " ", combined_data$Week)
tidied_data<- combined_data|>
  mutate(Week = time)




```

```{r}
# make a spaghetti plot showing observations on each subject over time
ggplot(tidied_data, 
       aes(x = factor(time), y = Observations, group = subject_id, color = subject_id)) +
  geom_point() +
  geom_line() +
  facet_grid(.~arm) +
  labs(
    title = "Spaghetti Plot of Observations Over Time",
    x = "Time",
    y = "Value",
    color = "Subject ID"
  ) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

```

Based on the spaghetti graph, we can clearly see that the control arms from the longitudinal study have lower observation values compared to experimental arms, and the experimental arms fluctuate more frequent than control arms.
 
### Problem 3
```{r}

# Set parameters, two-sided
set.seed(5000)
n <- 30
sigma <- 5
dataset <- 5000
alpha <- 0.05

#function for test of H:μ=0 using α=0.05 when mu = 0
 
output = vector("list", length = 5000)
for (i in 1:5000) {
  sample_data <-tibble(x = rnorm(n, mean = 0, sd = sigma))
  output[[i]] = t.test(sample_data,mu = 0, conf.level = 0.95)|>
  broom::tidy()}
sample_test<-output|>
  bind_rows()|>
  select(estimate, p.value)|>
  mutate(mu = 0)
```

```{r}
# Repeat the simulation for mu = 1, 2, 3, 4, 5, 6
mu_values <- c(1, 2, 3, 4, 5, 6)
outputs <- vector("list", length = 5000)

for (i in 1:5000) {
  for (mu in mu_values) {
    sample_data <- tibble(x = rnorm(n, mean = mu, sd = sigma))
    result <- t.test(sample_data$x, mu = 0, conf.level = 0.95) |> 
      broom::tidy()
    result$mu <- mu  
    outputs[[length(outputs) + 1]] <- result
  }
}

sample_tests <- outputs |> 
  bind_rows() |> 
  select(mu, estimate, p.value)
```



```{r}
#Make a plot showing the proportion of times the null was rejected 

total_test <- bind_rows(sample_test,sample_tests)|>
  group_by(mu)
  

plot_1<- total_test|>
  summarize(rejected_null = sum(p.value < 0.05),total = n()) |>
  mutate(proportion = rejected_null / total) |> 
  ggplot(aes(x = mu, y = proportion,color=mu)) +
  geom_point() +
  geom_line()+
  labs(title = "Proportion of times the null rejected based μ",
       x = "Value of μ",
       y = "Proportion",
       caption = "Effect size is positively associated with power") 

plot_1
```
The association between effect size and power is that effect size is positively associated with power.

```{r}
#Make a plot showing the average estimate of μ on the y axis and the true value of μ on the x axis.

plot_2<- total_test|>
  summarize(average_mu_values = mean(estimate))|>
  ggplot(aes(x = mu, y = average_mu_values,color=mu)) + 
  geom_point() +
  geom_line() +
  labs(title = "Average Estimate of mu Versus True Value of mu",
       x = "True Value of mu",
       y = "Average Estimate of mu") 

#Make a second plot he average estimate of μ only in samples for which the null was rejected on the y axis and the true value of μ on the x axis.          
plot_3<- total_test|>
  filter(p.value < 0.05)|>
  summarize(new_average_mu_values = mean(estimate))|>
  ggplot(aes(x = mu, y = new_average_mu_values,color=mu)) + 
  geom_point() +
  geom_line() +
  labs(title = "Average Estimate of mu Versus True Value of mu When Null was Rejected",
       x = "True Value of mu",
       y = "Average Estimate of mu when null was rejected") 
  

  
```
```{r patchwork}
plot_2 + plot_3
```
From the graph, we can see that the average estimate of mu is almost the same as true value of mu. But for samples are only the null that was rejected, when the power move from 0 to 3, the derivation of average estimate of mu is larger compared with true value of mu. But when the power move from 4 to 6, the average estimate of mu becomes almost the same as true value of mu.

